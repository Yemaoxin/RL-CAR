{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the NN enough to identify LRU or LFU indices?\n",
    "\n",
    "In this notebook I check if the nn for my DQN even capable of doing its task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "from e2 import CacheEnv\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<os_sim.OS object at 0x7f6fefeeaa58>\n",
      "Cache limit: 10\n",
      "Total Pages: 20\n"
     ]
    }
   ],
   "source": [
    "# env vars\n",
    "EPS_LEN = 100\n",
    "N_PAGES = 20\n",
    "CACHE_LIMIT = 10 \n",
    "env = CacheEnv(\n",
    "        eps_len=EPS_LEN, \n",
    "        n_pages=N_PAGES, \n",
    "        limit=CACHE_LIMIT\n",
    "        )\n",
    "\n",
    "# dqn vars\n",
    "# N_EPS = 60000\n",
    "N_EPS = 1000\n",
    "BATCH_SIZE = 32\n",
    "LR_adam = 3e-4                   # learning rate for Adam\n",
    "LR_sgd = 1e-3                   # learning rate for SGD\n",
    "EPSILON = 0.9               # greedy policy\n",
    "GAMMA = 0.9                 # reward discount\n",
    "TARGET_REPLACE_ITER = 2000   # target update frequency\n",
    "MEMORY_CAPACITY = 20000\n",
    "\n",
    "s = env.reset()\n",
    "N_ACTIONS = env.action_space_n\n",
    "STATE_SHAPE = (CACHE_LIMIT, 2)\n",
    "N_STATES = STATE_SHAPE[0]*STATE_SHAPE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c611fdce06c14ad59cd0fdd02766d829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "101000\n"
     ]
    }
   ],
   "source": [
    "# Collect data\n",
    "dataX = []\n",
    "for _ in tqdm(range(N_EPS)):\n",
    "    s = env.reset()\n",
    "    dataX.append(s)\n",
    "\n",
    "    while True:\n",
    "        a = np.random.randint(0, N_ACTIONS)\n",
    "        s, _, done, _ = env.step(a)\n",
    "        dataX.append(s)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print(len(dataX))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b9baec29524318b81ee1fc4ca0710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_labels(dataX):\n",
    "    dataYLU = []\n",
    "    dataYRU = [] \n",
    "    for x in tqdm(dataX):\n",
    "        lus = np.argmin(x[::2])\n",
    "        rus = np.argmin(x[1::2])\n",
    "        dataYLU.append(lus)\n",
    "        dataYRU.append(rus)\n",
    "    return dataYLU, dataYRU     \n",
    "        \n",
    "dataYLU, dataYRU = get_labels(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "101000\n",
      "101000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataYLU))\n",
    "print(len(dataYRU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "101000\n",
      "80800\n",
      "20200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataX\n",
    "Y = dataYLU\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.2)\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "print(len(XTrain))\n",
    "print(len(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.targets = torch.LongTensor(targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CacheDataset(XTrain, yTrain)\n",
    "test_dataset = CacheDataset(XTest, yTest)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        input_size = N_STATES\n",
    "        h_dim = 50\n",
    "        self.fc1 = nn.Linear(input_size, h_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, h_dim//4)\n",
    "        self.bn2 = nn.BatchNorm1d(h_dim//4)\n",
    "        self.fc3 = nn.Linear(h_dim//4, h_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(h_dim)\n",
    "        self.out = nn.Linear(h_dim, N_ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         bs = x.shape[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.out(x)\n",
    "#         return x\n",
    "        return F.softmax(x, dim=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eeaff486d9a4cdba33942ca5840c427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] | Loss: 2.187633514404297\n",
      "Epoch: [1] | Loss: 2.144232749938965\n",
      "Epoch: [2] | Loss: 2.1371021270751953\n",
      "Epoch: [3] | Loss: 2.1437060832977295\n",
      "Epoch: [4] | Loss: 2.121243715286255\n",
      "Epoch: [5] | Loss: 2.1124751567840576\n",
      "Epoch: [6] | Loss: 2.105055093765259\n",
      "Epoch: [7] | Loss: 2.0993552207946777\n",
      "Epoch: [8] | Loss: 2.0964062213897705\n",
      "Epoch: [9] | Loss: 2.0916545391082764\n",
      "Epoch: [10] | Loss: 2.0877633094787598\n",
      "Epoch: [11] | Loss: 2.085021734237671\n",
      "Epoch: [12] | Loss: 2.0823757648468018\n",
      "Epoch: [13] | Loss: 2.0809569358825684\n",
      "Epoch: [14] | Loss: 2.0783753395080566\n",
      "Epoch: [15] | Loss: 2.075209140777588\n",
      "Epoch: [16] | Loss: 2.0703678131103516\n",
      "Epoch: [17] | Loss: 2.0702061653137207\n",
      "Epoch: [18] | Loss: 2.066880702972412\n",
      "Epoch: [19] | Loss: 2.0660462379455566\n",
      "Epoch: [20] | Loss: 2.0639312267303467\n",
      "Epoch: [21] | Loss: 2.061947822570801\n",
      "Epoch: [22] | Loss: 2.060666561126709\n",
      "Epoch: [23] | Loss: 2.059048891067505\n",
      "Epoch: [24] | Loss: 2.057486057281494\n",
      "Epoch: [25] | Loss: 2.0560691356658936\n",
      "Epoch: [26] | Loss: 2.0552005767822266\n",
      "Epoch: [27] | Loss: 2.056312322616577\n",
      "Epoch: [28] | Loss: 2.0555484294891357\n",
      "Epoch: [29] | Loss: 2.0530333518981934\n",
      "Epoch: [30] | Loss: 2.063065767288208\n",
      "Epoch: [31] | Loss: 2.0705971717834473\n",
      "Epoch: [32] | Loss: 2.0673348903656006\n",
      "Epoch: [33] | Loss: 2.0656776428222656\n",
      "Epoch: [34] | Loss: 2.0652015209198\n",
      "Epoch: [35] | Loss: 2.0645012855529785\n",
      "Epoch: [36] | Loss: 2.0647106170654297\n",
      "Epoch: [37] | Loss: 2.063448667526245\n",
      "Epoch: [38] | Loss: 2.0621421337127686\n",
      "Epoch: [39] | Loss: 2.063877582550049\n",
      "Epoch: [40] | Loss: 2.0610716342926025\n",
      "Epoch: [41] | Loss: 2.0602352619171143\n",
      "Epoch: [42] | Loss: 2.0598061084747314\n",
      "Epoch: [43] | Loss: 2.0579872131347656\n",
      "Epoch: [44] | Loss: 2.0548243522644043\n",
      "Epoch: [45] | Loss: 2.0516254901885986\n",
      "Epoch: [46] | Loss: 2.0497026443481445\n",
      "Epoch: [47] | Loss: 2.048828125\n",
      "Epoch: [48] | Loss: 2.0497946739196777\n",
      "Epoch: [49] | Loss: 2.0482306480407715\n",
      "Epoch: [50] | Loss: 2.0477547645568848\n",
      "Epoch: [51] | Loss: 2.0470199584960938\n",
      "Epoch: [52] | Loss: 2.0468432903289795\n",
      "Epoch: [53] | Loss: 2.0469202995300293\n",
      "Epoch: [54] | Loss: 2.046201229095459\n",
      "Epoch: [55] | Loss: 2.0457727909088135\n",
      "Epoch: [56] | Loss: 2.0458312034606934\n",
      "Epoch: [57] | Loss: 2.045846939086914\n",
      "Epoch: [58] | Loss: 2.0454676151275635\n",
      "Epoch: [59] | Loss: 2.045536518096924\n",
      "Epoch: [60] | Loss: 2.0453977584838867\n",
      "Epoch: [61] | Loss: 2.045363187789917\n",
      "Epoch: [62] | Loss: 2.045435905456543\n",
      "Epoch: [63] | Loss: 2.045151710510254\n",
      "Epoch: [64] | Loss: 2.0454161167144775\n",
      "Epoch: [65] | Loss: 2.045161008834839\n",
      "Epoch: [66] | Loss: 2.045203924179077\n",
      "Epoch: [67] | Loss: 2.0451138019561768\n",
      "Epoch: [68] | Loss: 2.044893264770508\n",
      "Epoch: [69] | Loss: 2.0448856353759766\n",
      "Epoch: [70] | Loss: 2.0448765754699707\n",
      "Epoch: [71] | Loss: 2.0448691844940186\n",
      "Epoch: [72] | Loss: 2.044767379760742\n",
      "Epoch: [73] | Loss: 2.0447545051574707\n",
      "Epoch: [74] | Loss: 2.0446510314941406\n",
      "Epoch: [75] | Loss: 2.0445046424865723\n",
      "Epoch: [76] | Loss: 2.044635057449341\n",
      "Epoch: [77] | Loss: 2.044440746307373\n",
      "Epoch: [78] | Loss: 2.0449013710021973\n",
      "Epoch: [79] | Loss: 2.044398307800293\n",
      "Epoch: [80] | Loss: 2.0446112155914307\n",
      "Epoch: [81] | Loss: 2.046970844268799\n",
      "Epoch: [82] | Loss: 2.0472493171691895\n",
      "Epoch: [83] | Loss: 2.045949935913086\n",
      "Epoch: [84] | Loss: 2.045917510986328\n",
      "Epoch: [85] | Loss: 2.0451414585113525\n",
      "Epoch: [86] | Loss: 2.0451531410217285\n",
      "Epoch: [87] | Loss: 2.0451693534851074\n",
      "Epoch: [88] | Loss: 2.0447967052459717\n",
      "Epoch: [89] | Loss: 2.044837474822998\n",
      "Epoch: [90] | Loss: 2.044792413711548\n",
      "Epoch: [91] | Loss: 2.0447239875793457\n",
      "Epoch: [92] | Loss: 2.0448155403137207\n",
      "Epoch: [93] | Loss: 2.0446364879608154\n",
      "Epoch: [94] | Loss: 2.044811248779297\n",
      "Epoch: [95] | Loss: 2.044571876525879\n",
      "Epoch: [96] | Loss: 2.0447733402252197\n",
      "Epoch: [97] | Loss: 2.0447912216186523\n",
      "Epoch: [98] | Loss: 2.0448620319366455\n",
      "Epoch: [99] | Loss: 2.044692039489746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().cuda()\n",
    "LR_adam = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_adam)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\n",
    "# loss_func = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    totalloss = []\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss.append(loss.detach().cpu().numpy())\n",
    "    totalloss = np.array(totalloss).mean()\n",
    "    print(f\"Epoch: [{epoch}] | Loss: {totalloss}\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "LR_adam = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_adam)\n",
    "# LR_sgd = 1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\n",
    "# loss_func = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    totalloss = []\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss.append(loss.detach().cpu().numpy())\n",
    "    totalloss = np.array(totalloss).mean()\n",
    "    print(f\"Epoch: [{epoch}] | Loss: {totalloss}\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
