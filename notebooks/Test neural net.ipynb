{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the NN enough to identify LRU or LFU indices?\n",
    "\n",
    "In this notebook I check if the nn for my DQN even capable of doing its task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "from e2 import CacheEnv\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<os_sim.OS object at 0x7fab3159ee80>\n",
      "Cache limit: 10\n",
      "Total Pages: 20\n"
     ]
    }
   ],
   "source": [
    "# env vars\n",
    "EPS_LEN = 100\n",
    "N_PAGES = 20\n",
    "CACHE_LIMIT = 10 \n",
    "env = CacheEnv(\n",
    "        eps_len=EPS_LEN, \n",
    "        n_pages=N_PAGES, \n",
    "        limit=CACHE_LIMIT\n",
    "        )\n",
    "\n",
    "# dqn vars\n",
    "# N_EPS = 60000\n",
    "N_EPS = 1000\n",
    "BATCH_SIZE = 32\n",
    "LR_adam = 3e-4                   # learning rate for Adam\n",
    "LR_sgd = 1e-3                   # learning rate for SGD\n",
    "EPSILON = 0.9               # greedy policy\n",
    "GAMMA = 0.9                 # reward discount\n",
    "TARGET_REPLACE_ITER = 2000   # target update frequency\n",
    "MEMORY_CAPACITY = 20000\n",
    "\n",
    "s = env.reset()\n",
    "N_ACTIONS = env.action_space_n\n",
    "STATE_SHAPE = (CACHE_LIMIT, 2)\n",
    "N_STATES = STATE_SHAPE[0]*STATE_SHAPE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf568c72e3349548ed9e7bd3ceddd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "101000\n"
     ]
    }
   ],
   "source": [
    "# Collect data\n",
    "dataX = []\n",
    "for _ in tqdm(range(N_EPS)):\n",
    "    s = env.reset()\n",
    "    dataX.append(s)\n",
    "\n",
    "    while True:\n",
    "        a = np.random.randint(0, N_ACTIONS)\n",
    "        s, _, done, _ = env.step(a)\n",
    "        dataX.append(s)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print(len(dataX))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ce16e9a209413db01bf260c5431639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_labels(dataX):\n",
    "    dataYLU = []\n",
    "    dataYRU = [] \n",
    "    for x in tqdm(dataX):\n",
    "        lus = np.argmin(x[::2])\n",
    "        rus = np.argmin(x[1::2])\n",
    "        dataYLU.append(lus)\n",
    "        dataYRU.append(rus)\n",
    "    return dataYLU, dataYRU     \n",
    "        \n",
    "dataYLU, dataYRU = get_labels(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "101000\n",
      "101000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataYLU))\n",
    "print(len(dataYRU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "101000\n",
      "80800\n",
      "20200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataX\n",
    "Y = dataYLU\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.2)\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "print(len(XTrain))\n",
    "print(len(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.targets = torch.LongTensor(targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CacheDataset(XTrain, yTrain)\n",
    "test_dataset = CacheDataset(XTest, yTest)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        input_size = N_STATES\n",
    "        h_dim = 50\n",
    "        self.fc1 = nn.Linear(input_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, h_dim//4)\n",
    "#         self.fc3 = nn.Linear(h_dim//4, h_dim)\n",
    "        self.out = nn.Linear(h_dim//4, N_ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         bs = x.shape[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "#         return x\n",
    "        return F.softmax(x, dim=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfca94909e624645bf9dc744f8e29d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] | Loss: 2.259532928466797\n",
      "Epoch: [1] | Loss: 2.220102310180664\n",
      "Epoch: [2] | Loss: 2.2002053260803223\n",
      "Epoch: [3] | Loss: 2.1833508014678955\n",
      "Epoch: [4] | Loss: 2.1603164672851562\n",
      "Epoch: [5] | Loss: 2.128648042678833\n",
      "Epoch: [6] | Loss: 2.093916416168213\n",
      "Epoch: [7] | Loss: 2.0518012046813965\n",
      "Epoch: [8] | Loss: 2.046609401702881\n",
      "Epoch: [9] | Loss: 2.0448379516601562\n",
      "Epoch: [10] | Loss: 2.043445587158203\n",
      "Epoch: [11] | Loss: 2.0426876544952393\n",
      "Epoch: [12] | Loss: 2.0422677993774414\n",
      "Epoch: [13] | Loss: 2.041914939880371\n",
      "Epoch: [14] | Loss: 2.0413691997528076\n",
      "Epoch: [15] | Loss: 2.0413410663604736\n",
      "Epoch: [16] | Loss: 2.040956497192383\n",
      "Epoch: [17] | Loss: 2.04116153717041\n",
      "Epoch: [18] | Loss: 2.040792942047119\n",
      "Epoch: [19] | Loss: 2.0409271717071533\n",
      "Epoch: [20] | Loss: 2.0407297611236572\n",
      "Epoch: [21] | Loss: 2.040729522705078\n",
      "Epoch: [22] | Loss: 2.040194272994995\n",
      "Epoch: [23] | Loss: 2.040257215499878\n",
      "Epoch: [24] | Loss: 2.040501356124878\n",
      "Epoch: [25] | Loss: 2.040241241455078\n",
      "Epoch: [26] | Loss: 2.040013074874878\n",
      "Epoch: [27] | Loss: 2.0399413108825684\n",
      "Epoch: [28] | Loss: 2.040330410003662\n",
      "Epoch: [29] | Loss: 2.0394999980926514\n",
      "Epoch: [30] | Loss: 2.039804697036743\n",
      "Epoch: [31] | Loss: 2.0395517349243164\n",
      "Epoch: [32] | Loss: 2.0401785373687744\n",
      "Epoch: [33] | Loss: 2.039236068725586\n",
      "Epoch: [34] | Loss: 2.0395801067352295\n",
      "Epoch: [35] | Loss: 2.039592981338501\n",
      "Epoch: [36] | Loss: 2.039630174636841\n",
      "Epoch: [37] | Loss: 2.0395522117614746\n",
      "Epoch: [38] | Loss: 2.039728879928589\n",
      "Epoch: [39] | Loss: 2.039689540863037\n",
      "Epoch: [40] | Loss: 2.0394980907440186\n",
      "Epoch: [41] | Loss: 2.0395913124084473\n",
      "Epoch: [42] | Loss: 2.0392074584960938\n",
      "Epoch: [43] | Loss: 2.039278030395508\n",
      "Epoch: [44] | Loss: 2.039339303970337\n",
      "Epoch: [45] | Loss: 2.039569139480591\n",
      "Epoch: [46] | Loss: 2.0392656326293945\n",
      "Epoch: [47] | Loss: 2.039586305618286\n",
      "Epoch: [48] | Loss: 2.039689779281616\n",
      "Epoch: [49] | Loss: 2.038933038711548\n",
      "Epoch: [50] | Loss: 2.040221691131592\n",
      "Epoch: [51] | Loss: 2.0389926433563232\n",
      "Epoch: [52] | Loss: 2.0393753051757812\n",
      "Epoch: [53] | Loss: 2.0391385555267334\n",
      "Epoch: [54] | Loss: 2.039254665374756\n",
      "Epoch: [55] | Loss: 2.0390257835388184\n",
      "Epoch: [56] | Loss: 2.039168357849121\n",
      "Epoch: [57] | Loss: 2.0392825603485107\n",
      "Epoch: [58] | Loss: 2.0397140979766846\n",
      "Epoch: [59] | Loss: 2.0390145778656006\n",
      "Epoch: [60] | Loss: 2.0388970375061035\n",
      "Epoch: [61] | Loss: 2.0390872955322266\n",
      "Epoch: [62] | Loss: 2.0389273166656494\n",
      "Epoch: [63] | Loss: 2.0390305519104004\n",
      "Epoch: [64] | Loss: 2.03910493850708\n",
      "Epoch: [65] | Loss: 2.03894305229187\n",
      "Epoch: [66] | Loss: 2.0399632453918457\n",
      "Epoch: [67] | Loss: 2.0392112731933594\n",
      "Epoch: [68] | Loss: 2.039066791534424\n",
      "Epoch: [69] | Loss: 2.0389139652252197\n",
      "Epoch: [70] | Loss: 2.038849115371704\n",
      "Epoch: [71] | Loss: 2.039476156234741\n",
      "Epoch: [72] | Loss: 2.0388786792755127\n",
      "Epoch: [73] | Loss: 2.039260149002075\n",
      "Epoch: [74] | Loss: 2.038881778717041\n",
      "Epoch: [75] | Loss: 2.0390172004699707\n",
      "Epoch: [76] | Loss: 2.038696050643921\n",
      "Epoch: [77] | Loss: 2.038752794265747\n",
      "Epoch: [78] | Loss: 2.0390288829803467\n",
      "Epoch: [79] | Loss: 2.0388009548187256\n",
      "Epoch: [80] | Loss: 2.039278984069824\n",
      "Epoch: [81] | Loss: 2.039017915725708\n",
      "Epoch: [82] | Loss: 2.0387163162231445\n",
      "Epoch: [83] | Loss: 2.0388920307159424\n",
      "Epoch: [84] | Loss: 2.0392041206359863\n",
      "Epoch: [85] | Loss: 2.038804054260254\n",
      "Epoch: [86] | Loss: 2.038860321044922\n",
      "Epoch: [87] | Loss: 2.038860321044922\n",
      "Epoch: [88] | Loss: 2.038773536682129\n",
      "Epoch: [89] | Loss: 2.0389082431793213\n",
      "Epoch: [90] | Loss: 2.0386264324188232\n",
      "Epoch: [91] | Loss: 2.0389020442962646\n",
      "Epoch: [92] | Loss: 2.0388686656951904\n",
      "Epoch: [93] | Loss: 2.038672685623169\n",
      "Epoch: [94] | Loss: 2.03863263130188\n",
      "Epoch: [95] | Loss: 2.03869366645813\n",
      "Epoch: [96] | Loss: 2.038816213607788\n",
      "Epoch: [97] | Loss: 2.038607597351074\n",
      "Epoch: [98] | Loss: 2.039083480834961\n",
      "Epoch: [99] | Loss: 2.0384867191314697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().cuda()\n",
    "LR_adam = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_adam)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\n",
    "# loss_func = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    totalloss = []\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss.append(loss.detach().cpu().numpy())\n",
    "    totalloss = np.array(totalloss).mean()\n",
    "    print(f\"Epoch: [{epoch}] | Loss: {totalloss}\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4642ae24a11146c2bba02067a2ed0e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] | Loss: 2.2546284198760986\n",
      "Epoch: [1] | Loss: 2.1946310997009277\n",
      "Epoch: [2] | Loss: 2.1658849716186523\n",
      "Epoch: [3] | Loss: 2.1551766395568848\n",
      "Epoch: [4] | Loss: 2.1485772132873535\n",
      "Epoch: [5] | Loss: 2.1315369606018066\n",
      "Epoch: [6] | Loss: 2.1016390323638916\n",
      "Epoch: [7] | Loss: 2.0723493099212646\n",
      "Epoch: [8] | Loss: 2.0560410022735596\n",
      "Epoch: [9] | Loss: 2.0498576164245605\n",
      "Epoch: [10] | Loss: 2.0476937294006348\n",
      "Epoch: [11] | Loss: 2.0468590259552\n",
      "Epoch: [12] | Loss: 2.0463180541992188\n",
      "Epoch: [13] | Loss: 2.0460495948791504\n",
      "Epoch: [14] | Loss: 2.045947790145874\n",
      "Epoch: [15] | Loss: 2.045693874359131\n",
      "Epoch: [16] | Loss: 2.0456440448760986\n",
      "Epoch: [17] | Loss: 2.045503616333008\n",
      "Epoch: [18] | Loss: 2.0453832149505615\n",
      "Epoch: [19] | Loss: 2.0452992916107178\n",
      "Epoch: [20] | Loss: 2.0451860427856445\n",
      "Epoch: [21] | Loss: 2.045102596282959\n",
      "Epoch: [22] | Loss: 2.044992208480835\n",
      "Epoch: [23] | Loss: 2.044844627380371\n",
      "Epoch: [24] | Loss: 2.044734239578247\n",
      "Epoch: [25] | Loss: 2.0446269512176514\n",
      "Epoch: [26] | Loss: 2.0444576740264893\n",
      "Epoch: [27] | Loss: 2.044301986694336\n",
      "Epoch: [28] | Loss: 2.0442354679107666\n",
      "Epoch: [29] | Loss: 2.0441060066223145\n",
      "Epoch: [30] | Loss: 2.0439844131469727\n",
      "Epoch: [31] | Loss: 2.0438575744628906\n",
      "Epoch: [32] | Loss: 2.0437779426574707\n",
      "Epoch: [33] | Loss: 2.043729066848755\n",
      "Epoch: [34] | Loss: 2.0436296463012695\n",
      "Epoch: [35] | Loss: 2.0435824394226074\n",
      "Epoch: [36] | Loss: 2.043461799621582\n",
      "Epoch: [37] | Loss: 2.043421506881714\n",
      "Epoch: [38] | Loss: 2.043349504470825\n",
      "Epoch: [39] | Loss: 2.043292999267578\n",
      "Epoch: [40] | Loss: 2.0432193279266357\n",
      "Epoch: [41] | Loss: 2.0432820320129395\n",
      "Epoch: [42] | Loss: 2.0431628227233887\n",
      "Epoch: [43] | Loss: 2.0430920124053955\n",
      "Epoch: [44] | Loss: 2.043161392211914\n",
      "Epoch: [45] | Loss: 2.0430634021759033\n",
      "Epoch: [46] | Loss: 2.043029546737671\n",
      "Epoch: [47] | Loss: 2.0429415702819824\n",
      "Epoch: [48] | Loss: 2.0429136753082275\n",
      "Epoch: [49] | Loss: 2.0428225994110107\n",
      "Epoch: [50] | Loss: 2.0427842140197754\n",
      "Epoch: [51] | Loss: 2.042729377746582\n",
      "Epoch: [52] | Loss: 2.042661428451538\n",
      "Epoch: [53] | Loss: 2.0426313877105713\n",
      "Epoch: [54] | Loss: 2.042609930038452\n",
      "Epoch: [55] | Loss: 2.042605400085449\n",
      "Epoch: [56] | Loss: 2.0423998832702637\n",
      "Epoch: [57] | Loss: 2.0423569679260254\n",
      "Epoch: [58] | Loss: 2.042381763458252\n",
      "Epoch: [59] | Loss: 2.0422234535217285\n",
      "Epoch: [60] | Loss: 2.042184352874756\n",
      "Epoch: [61] | Loss: 2.042114019393921\n",
      "Epoch: [62] | Loss: 2.0420751571655273\n",
      "Epoch: [63] | Loss: 2.0420069694519043\n",
      "Epoch: [64] | Loss: 2.0419962406158447\n",
      "Epoch: [65] | Loss: 2.0418896675109863\n",
      "Epoch: [66] | Loss: 2.0418474674224854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-83b93495935c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-125f2ececb8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         bs = x.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         x = F.relu(self.fc3(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net().cuda()\n",
    "LR_adam = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_adam)\n",
    "# LR_sgd = 1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\n",
    "# loss_func = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    totalloss = []\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss.append(loss.detach().cpu().numpy())\n",
    "    totalloss = np.array(totalloss).mean()\n",
    "    print(f\"Epoch: [{epoch}] | Loss: {totalloss}\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
