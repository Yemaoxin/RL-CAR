{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the NN enough to identify LRU or LFU indices?\n",
    "\n",
    "In this notebook I check if the nn for my DQN even capable of doing its task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "from e2 import CacheEnv\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<os_sim.OS object at 0x7f6fefeeaa58>\n",
      "Cache limit: 10\n",
      "Total Pages: 20\n"
     ]
    }
   ],
   "source": [
    "# env vars\n",
    "EPS_LEN = 100\n",
    "N_PAGES = 20\n",
    "CACHE_LIMIT = 10 \n",
    "env = CacheEnv(\n",
    "        eps_len=EPS_LEN, \n",
    "        n_pages=N_PAGES, \n",
    "        limit=CACHE_LIMIT\n",
    "        )\n",
    "\n",
    "# dqn vars\n",
    "# N_EPS = 60000\n",
    "N_EPS = 1000\n",
    "BATCH_SIZE = 32\n",
    "LR_adam = 3e-4                   # learning rate for Adam\n",
    "LR_sgd = 1e-3                   # learning rate for SGD\n",
    "EPSILON = 0.9               # greedy policy\n",
    "GAMMA = 0.9                 # reward discount\n",
    "TARGET_REPLACE_ITER = 2000   # target update frequency\n",
    "MEMORY_CAPACITY = 20000\n",
    "\n",
    "s = env.reset()\n",
    "N_ACTIONS = env.action_space_n\n",
    "STATE_SHAPE = (CACHE_LIMIT, 2)\n",
    "N_STATES = STATE_SHAPE[0]*STATE_SHAPE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c611fdce06c14ad59cd0fdd02766d829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "101000\n"
     ]
    }
   ],
   "source": [
    "# Collect data\n",
    "dataX = []\n",
    "for _ in tqdm(range(N_EPS)):\n",
    "    s = env.reset()\n",
    "    dataX.append(s)\n",
    "\n",
    "    while True:\n",
    "        a = np.random.randint(0, N_ACTIONS)\n",
    "        s, _, done, _ = env.step(a)\n",
    "        dataX.append(s)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print(len(dataX))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b9baec29524318b81ee1fc4ca0710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_labels(dataX):\n",
    "    dataYLU = []\n",
    "    dataYRU = [] \n",
    "    for x in tqdm(dataX):\n",
    "        lus = np.argmin(x[::2])\n",
    "        rus = np.argmin(x[1::2])\n",
    "        dataYLU.append(lus)\n",
    "        dataYRU.append(rus)\n",
    "    return dataYLU, dataYRU     \n",
    "        \n",
    "dataYLU, dataYRU = get_labels(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "101000\n",
      "101000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataYLU))\n",
    "print(len(dataYRU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101000\n",
      "101000\n",
      "80800\n",
      "20200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataX\n",
    "Y = dataYLU\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.2)\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "print(len(XTrain))\n",
    "print(len(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.targets = torch.LongTensor(targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CacheDataset(XTrain, yTrain)\n",
    "test_dataset = CacheDataset(XTest, yTest)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        input_size = N_STATES\n",
    "        h_dim = 50\n",
    "        self.fc1 = nn.Linear(input_size, h_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, h_dim//4)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim//4)\n",
    "        self.fc3 = nn.Linear(h_dim//4, h_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)\n",
    "        self.out = nn.Linear(h_dim//4, N_ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         bs = x.shape[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "#         return x\n",
    "        return F.softmax(x, dim=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'num_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-732225480e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLR_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# loss_func = nn.MSELoss()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-fd63eb5c104d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_STATES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mh_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dim\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_features'"
     ]
    }
   ],
   "source": [
    "model = Net().cuda()\n",
    "LR_adam = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_adam)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\n",
    "# loss_func = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    totalloss = []\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss.append(loss.detach().cpu().numpy())\n",
    "    totalloss = np.array(totalloss).mean()\n",
    "    print(f\"Epoch: [{epoch}] | Loss: {totalloss}\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4642ae24a11146c2bba02067a2ed0e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] | Loss: 2.2546284198760986\n",
      "Epoch: [1] | Loss: 2.1946310997009277\n",
      "Epoch: [2] | Loss: 2.1658849716186523\n",
      "Epoch: [3] | Loss: 2.1551766395568848\n",
      "Epoch: [4] | Loss: 2.1485772132873535\n",
      "Epoch: [5] | Loss: 2.1315369606018066\n",
      "Epoch: [6] | Loss: 2.1016390323638916\n",
      "Epoch: [7] | Loss: 2.0723493099212646\n",
      "Epoch: [8] | Loss: 2.0560410022735596\n",
      "Epoch: [9] | Loss: 2.0498576164245605\n",
      "Epoch: [10] | Loss: 2.0476937294006348\n",
      "Epoch: [11] | Loss: 2.0468590259552\n",
      "Epoch: [12] | Loss: 2.0463180541992188\n",
      "Epoch: [13] | Loss: 2.0460495948791504\n",
      "Epoch: [14] | Loss: 2.045947790145874\n",
      "Epoch: [15] | Loss: 2.045693874359131\n",
      "Epoch: [16] | Loss: 2.0456440448760986\n",
      "Epoch: [17] | Loss: 2.045503616333008\n",
      "Epoch: [18] | Loss: 2.0453832149505615\n",
      "Epoch: [19] | Loss: 2.0452992916107178\n",
      "Epoch: [20] | Loss: 2.0451860427856445\n",
      "Epoch: [21] | Loss: 2.045102596282959\n",
      "Epoch: [22] | Loss: 2.044992208480835\n",
      "Epoch: [23] | Loss: 2.044844627380371\n",
      "Epoch: [24] | Loss: 2.044734239578247\n",
      "Epoch: [25] | Loss: 2.0446269512176514\n",
      "Epoch: [26] | Loss: 2.0444576740264893\n",
      "Epoch: [27] | Loss: 2.044301986694336\n",
      "Epoch: [28] | Loss: 2.0442354679107666\n",
      "Epoch: [29] | Loss: 2.0441060066223145\n",
      "Epoch: [30] | Loss: 2.0439844131469727\n",
      "Epoch: [31] | Loss: 2.0438575744628906\n",
      "Epoch: [32] | Loss: 2.0437779426574707\n",
      "Epoch: [33] | Loss: 2.043729066848755\n",
      "Epoch: [34] | Loss: 2.0436296463012695\n",
      "Epoch: [35] | Loss: 2.0435824394226074\n",
      "Epoch: [36] | Loss: 2.043461799621582\n",
      "Epoch: [37] | Loss: 2.043421506881714\n",
      "Epoch: [38] | Loss: 2.043349504470825\n",
      "Epoch: [39] | Loss: 2.043292999267578\n",
      "Epoch: [40] | Loss: 2.0432193279266357\n",
      "Epoch: [41] | Loss: 2.0432820320129395\n",
      "Epoch: [42] | Loss: 2.0431628227233887\n",
      "Epoch: [43] | Loss: 2.0430920124053955\n",
      "Epoch: [44] | Loss: 2.043161392211914\n",
      "Epoch: [45] | Loss: 2.0430634021759033\n",
      "Epoch: [46] | Loss: 2.043029546737671\n",
      "Epoch: [47] | Loss: 2.0429415702819824\n",
      "Epoch: [48] | Loss: 2.0429136753082275\n",
      "Epoch: [49] | Loss: 2.0428225994110107\n",
      "Epoch: [50] | Loss: 2.0427842140197754\n",
      "Epoch: [51] | Loss: 2.042729377746582\n",
      "Epoch: [52] | Loss: 2.042661428451538\n",
      "Epoch: [53] | Loss: 2.0426313877105713\n",
      "Epoch: [54] | Loss: 2.042609930038452\n",
      "Epoch: [55] | Loss: 2.042605400085449\n",
      "Epoch: [56] | Loss: 2.0423998832702637\n",
      "Epoch: [57] | Loss: 2.0423569679260254\n",
      "Epoch: [58] | Loss: 2.042381763458252\n",
      "Epoch: [59] | Loss: 2.0422234535217285\n",
      "Epoch: [60] | Loss: 2.042184352874756\n",
      "Epoch: [61] | Loss: 2.042114019393921\n",
      "Epoch: [62] | Loss: 2.0420751571655273\n",
      "Epoch: [63] | Loss: 2.0420069694519043\n",
      "Epoch: [64] | Loss: 2.0419962406158447\n",
      "Epoch: [65] | Loss: 2.0418896675109863\n",
      "Epoch: [66] | Loss: 2.0418474674224854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-83b93495935c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-125f2ececb8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         bs = x.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         x = F.relu(self.fc3(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net().cuda()\n",
    "LR_adam = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_adam)\n",
    "# LR_sgd = 1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR_sgd)\n",
    "# loss_func = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    totalloss = []\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss.append(loss.detach().cpu().numpy())\n",
    "    totalloss = np.array(totalloss).mean()\n",
    "    print(f\"Epoch: [{epoch}] | Loss: {totalloss}\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
